{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import lucid.modelzoo.vision_models as models\n",
    "from lucid.misc.io import show\n",
    "import lucid.optvis.render as render\n",
    "from lucid.misc.io import show, load\n",
    "from lucid.misc.io.reading import read\n",
    "from lucid.misc.io.showing import _image_url\n",
    "from lucid.misc.gradient_override import gradient_override_map\n",
    "import lucid.scratch.web.svelte as lucid_svelte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.InceptionV1()\n",
    "model.load_graphdef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_str = read(\"https://gist.githubusercontent.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57/raw/aa66dd9dbf6b56649fa3fab83659b2acbf3cbfd1/map_clsloc.txt\")\n",
    "labels = [line[line.find(\" \"):].strip() for line in labels_str.split(\"\\n\")]\n",
    "labels = [label[label.find(\" \"):].strip().replace(\"_\", \" \") for label in labels]\n",
    "labels = [\"dummy\"] + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_class_spatial_attr(img, layer, label, override=None):\n",
    "  \"\"\"How much did spatial positions at a given layer effect a output class?\"\"\"\n",
    "\n",
    "  # Set up a graph for doing attribution...\n",
    "  with tf.Graph().as_default(), tf.Session(), gradient_override_map(override or {}):\n",
    "    t_input = tf.placeholder_with_default(img, [None, None, 3])\n",
    "    T = render.import_model(model, t_input, t_input)\n",
    "    \n",
    "    # Compute activations\n",
    "    acts = T(layer).eval()\n",
    "    \n",
    "    if label is None: return np.zeros(acts.shape[1:-1])\n",
    "    \n",
    "    # Compute gradient\n",
    "    score = T(\"softmax2_pre_activation\")[0, labels.index(label)]\n",
    "    t_grad = tf.gradients([score], [T(layer)])[0]   \n",
    "    grad = t_grad.eval({T(layer) : acts})\n",
    "    \n",
    "    # Linear approximation of effect of spatial position\n",
    "    return np.sum(acts * grad, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_spatial_spatial_attr(img, layer1, layer2, override=None):\n",
    "  \"\"\"Attribution between spatial positions in two different layers.\"\"\"\n",
    "\n",
    "  # Set up a graph for doing attribution...\n",
    "  with tf.Graph().as_default(), tf.Session(), gradient_override_map(override or {}):\n",
    "    t_input = tf.placeholder_with_default(img, [None, None, 3])\n",
    "    T = render.import_model(model, t_input, t_input)\n",
    "    \n",
    "    # Compute activations\n",
    "    acts1 = T(layer1).eval()\n",
    "    acts2 = T(layer2).eval({T(layer1) : acts1})\n",
    "    \n",
    "    # Construct gradient tensor\n",
    "    # Backprop from spatial position (n_x, n_y) in layer2 to layer1.\n",
    "    n_x, n_y = tf.placeholder(\"int32\", []), tf.placeholder(\"int32\", [])\n",
    "    layer2_mags = tf.sqrt(tf.reduce_sum(T(layer2)**2, -1))[0]\n",
    "    score = layer2_mags[n_x, n_y]\n",
    "    t_grad = tf.gradients([score], [T(layer1)])[0]\n",
    "    \n",
    "    # Compute attribution backwards from each positin in layer2\n",
    "    attrs = []\n",
    "    for i in range(acts2.shape[1]):\n",
    "      attrs_ = []\n",
    "      for j in range(acts2.shape[2]):\n",
    "        grad = t_grad.eval({n_x : i, n_y : j, T(layer1) : acts1})\n",
    "        # linear approximation of imapct\n",
    "        attr = np.sum(acts1 * grad, -1)[0]\n",
    "        attrs_.append(attr)\n",
    "      attrs.append(attrs_)\n",
    "  return np.asarray(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orange_blue(a,b,clip=False):\n",
    "  if clip:\n",
    "    a,b = np.maximum(a,0), np.maximum(b,0)\n",
    "  arr = np.stack([a, (a + b)/2., b], -1)\n",
    "  arr /= 1e-2 + np.abs(arr).max()/1.5\n",
    "  arr += 0.3\n",
    "  return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html_define_svelte SpatialWidget\n",
    "\n",
    "<div class=\"figure\" style=\"width: 500px; height: 250px; contain: strict;\">\n",
    "  <div class=\"outer\" on:mouseleave=\"set({pos2: undefined})\">\n",
    "    <img class=\"img\"  src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos1 == undefined)? hint1 : spritemap1[pos1[1]][pos1[0]]}}\">\n",
    "\n",
    "    <svg class=\"pointer_container\" viewBox=\"0 0 {{size1}} {{size1}}\">\n",
    "      {{#each xs1 as x}}\n",
    "      {{#each ys1 as y}}\n",
    "        <rect x={{x}} y={{y}} width=1 height=1\n",
    "          class={{(pos2 != undefined && x == pos2[0] && y == pos2[1])? \"selected\" : \"\"}}\n",
    "          on:mouseover=\"set({pos2: [x,y], pos1: undefined})\"></rect>\n",
    "      {{/each}}\n",
    "      {{/each}}\n",
    "    </svg> \n",
    "\n",
    "    <div class=\"label\">{{layer1}}</div>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"outer\" on:mouseleave=\"set({pos1: undefined})\">\n",
    "    <img class=\"img\" src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos2 == undefined)? hint2 : spritemap2[pos2[1]][pos2[0]]}}\">\n",
    "\n",
    "    <svg class=\"pointer_container\" viewBox=\"0 0 {{size2}} {{size2}}\">\n",
    "      {{#each xs2 as x}}\n",
    "      {{#each ys2 as y}}\n",
    "        <rect x={{x}} y={{y}} width=1 height=1\n",
    "          class={{(pos1 != undefined && x == pos1[0] && y == pos1[1])? \"selected\" : \"\"}}\n",
    "          on:mouseover=\"set({pos1: [x,y], pos2: undefined})\"></rect>\n",
    "      {{/each}}\n",
    "      {{/each}}\n",
    "    </svg> \n",
    "\n",
    "    <div class=\"label\">{{layer2}}</div>\n",
    "  </div>\n",
    "  \n",
    "</div>\n",
    "\n",
    "\n",
    "<style>\n",
    "\n",
    "  .outer{\n",
    "    width: 224px;\n",
    "    height: 224px;\n",
    "    display: inline-block;\n",
    "    margin-right: 2px;\n",
    "    position: relative;\n",
    "  }\n",
    "  .outer img, .outer svg {\n",
    "    position: absolute;\n",
    "    left: 0px;\n",
    "    top: 0px;\n",
    "    width: 224px;\n",
    "    height: 224px;\n",
    "    image-rendering: pixelated; \n",
    "  }\n",
    "  .attr {\n",
    "    opacity: 0.6;\n",
    "  }\n",
    "  .pointer_container {\n",
    "    z-index: 100;\n",
    "  }\n",
    "  .pointer_container rect {\n",
    "    opacity: 0;\n",
    "  }\n",
    "  .pointer_container .selected  {\n",
    "    opacity: 1;\n",
    "    fill: none;\n",
    "    stroke: hsl(24, 100%, 50%);\n",
    "    stroke-width: 0.1px;\n",
    "  }\n",
    "  .label{\n",
    "    position: absolute;\n",
    "    left: 0px;\n",
    "    top: 226px;\n",
    "    width: 224px;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<script>\n",
    "  function range(n){\n",
    "    return Array(n).fill().map((_, i) => i);\n",
    "  }\n",
    "  \n",
    "  export default {\n",
    "    data () {\n",
    "      return {\n",
    "        img: \"\",\n",
    "        hint1: \"\",\n",
    "        hint2: \"\",\n",
    "        spritemap1 : \"\",\n",
    "        size1: 1,\n",
    "        spritemap2 : \"\",\n",
    "        size2: 1,\n",
    "        pos1: undefined,\n",
    "        pos2: undefined,\n",
    "        layer1: \"\",\n",
    "        layer2: \"\"\n",
    "      };\n",
    "    },\n",
    "    computed: {\n",
    "      xs1: (size1) => range(size1),\n",
    "      ys1: (size1) => range(size1),\n",
    "      xs2: (size2) => range(size2),\n",
    "      ys2: (size2) => range(size2)\n",
    "    },\n",
    "    helpers: {range}\n",
    "  };\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_url_grid(grid):\n",
    "  return [[_image_url(img) for img in line] for line in grid ]\n",
    "\n",
    "def spatial_spatial_attr(img, layer1, layer2, hint_label_1=None, hint_label_2=None, override=None):\n",
    "  \n",
    "  hint1 = orange_blue(\n",
    "      raw_class_spatial_attr(img, layer1, hint_label_1, override=override),\n",
    "      raw_class_spatial_attr(img, layer1, hint_label_2, override=override),\n",
    "      clip=True\n",
    "  )\n",
    "  hint2 = orange_blue(\n",
    "      raw_class_spatial_attr(img, layer2, hint_label_1, override=override),\n",
    "      raw_class_spatial_attr(img, layer2, hint_label_2, override=override),\n",
    "      clip=True\n",
    "  )\n",
    "\n",
    "  attrs = raw_spatial_spatial_attr(img, layer1, layer2, override=override)\n",
    "  attrs = attrs / attrs.max()\n",
    "  \n",
    "  lucid_svelte.SpatialWidget({\n",
    "    \"spritemap1\": image_url_grid(attrs),\n",
    "    \"spritemap2\": image_url_grid(attrs.transpose(2,3,0,1)),\n",
    "    \"size1\": attrs.shape[3],\n",
    "    \"layer1\": layer1,\n",
    "    \"size2\": attrs.shape[0],\n",
    "    \"layer2\": layer2,\n",
    "    \"img\" : _image_url(img),\n",
    "    \"hint1\": _image_url(hint1),\n",
    "    \"hint2\": _image_url(hint2)\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load(\"https://storage.googleapis.com/lucid-static/building-blocks/examples/dog_cat.png\")\n",
    "\n",
    "spatial_spatial_attr(img, \"mixed4d\", \"mixed5a\", hint_label_1=\"Labrador retriever\", hint_label_2=\"tiger cat\")\n",
    "\n",
    "print \"\\nHover on images to interact! :D\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load(\"https://storage.googleapis.com/lucid-static/building-blocks/examples/dog_cat.png\")\n",
    "\n",
    "spatial_spatial_attr(img, \"mixed4a\", \"mixed4d\", hint_label_1=\"Labrador retriever\", hint_label_2=\"tiger cat\")\n",
    "\n",
    "print \"\\nHover on images to interact! :D\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur(x, w1, w2):\n",
    "  \"\"\"Spatially blur a 4D tensor.\"\"\"\n",
    "  x_ = tf.pad(x, [(0,0), (1,1), (1,1), (0,0)], \"CONSTANT\")\n",
    "  x_jitter_hv = (x_[:, 2:, 1:-1] + x_[:, :-2, 1:-1] + x_[:, 1:-1, 2:] + x_[:, 1:-1, :-2])/4.\n",
    "  x_jitter_diag = (x_[:, 2:, 2:] + x_[:, 2:, :-2] + x_[:, :-2, 2:] + x_[:, :-2, :-2])/4.\n",
    "  return (1-w1-w2)*x + w1*x_jitter_hv + w2*x_jitter_diag\n",
    "\n",
    "def make_MaxSmoothPoolGrad(blur_hack=False):\n",
    "  \"\"\"Create a relaxed version of the MaxPool gradient.\n",
    "  \n",
    "  GoogLeNet's use of MaxPooling creates a lot of gradient artifacts. This\n",
    "  function creates a fake gradient that gets rid of them, reducing distractions\n",
    "  in our UI demos.\n",
    "  \n",
    "  Be very very careful about using this in real life. It hides model behavior\n",
    "  from you. This can help you see other things more clearly, but in most cases\n",
    "  you probably should do something else.\n",
    "  \n",
    "  We're actively researching what's going on here.\n",
    "  \n",
    "  Args:\n",
    "    blur_hack: If True, use the second less principled trick of slightly\n",
    "      blurring the gradient to get rid of checkerboard artifacts.\n",
    "  \n",
    "  Returns:\n",
    "    Gradient function.\n",
    "    \n",
    "  \"\"\"\n",
    "  def MaxPoolGrad(op, grad):\n",
    "    inp = op.inputs[0]\n",
    "    \n",
    "    # Hack 1 (moderately principled): use a relaxation of the MaxPool grad\n",
    "    # ---------------------------------------------------------------------\n",
    "    #\n",
    "    # Construct a pooling function where, if we backprop through it,\n",
    "    # gradients get allocated proportional to the input activation.\n",
    "    # Then backpropr through that instead.\n",
    "    #\n",
    "    # In some ways, this is kind of spiritually similar to SmoothGrad\n",
    "    # (Smilkov et al.). To see the connection, note that MaxPooling introduces\n",
    "    # a pretty arbitrary discontinuity to your gradient; with the right\n",
    "    # distribution of input noise to the MaxPool op, you'd probably smooth out\n",
    "    # to this. It seems like this is one of the most natural ways to smooth.\n",
    "    #\n",
    "    # We'll probably talk about this and related things in future work.\n",
    "    \n",
    "    op_args = [op.get_attr(\"ksize\"), op.get_attr(\"strides\"), op.get_attr(\"padding\")]\n",
    "    smooth_out = tf.nn.avg_pool(inp**2, *op_args)/ (1e-2+tf.nn.avg_pool(tf.abs(inp), *op_args))\n",
    "    inp_smooth_grad = tf.gradients(smooth_out, [inp], grad)[0]\n",
    "    \n",
    "    # Hack 2 (if argument is set; not very principled) \n",
    "    # -------------------------------------------------\n",
    "    #\n",
    "    # Slightly blur gradient to get rid of checkerboard artifacts.\n",
    "    # Note, this really isn't principled. We're working around / hiding a bad\n",
    "    # property of the model. It should really be fixed by better model design.\n",
    "    #\n",
    "    # We do this so that the artifacts don't distract from the UI demo, but we\n",
    "    # don't endorse people doing it in real applications.\n",
    "    \n",
    "    if blur_hack:\n",
    "      inp_smooth_grad = blur(inp_smooth_grad, 0.5, 0.25)\n",
    "      \n",
    "    return inp_smooth_grad\n",
    "  return MaxPoolGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_attrs(img, layer1, layer2, hint_label_1, hint_label_2):\n",
    "  print \"Normal gradient:\\n\"\n",
    "\n",
    "  spatial_spatial_attr(img, layer1, layer2,\n",
    "                       hint_label_1=hint_label_1, hint_label_2=hint_label_2)\n",
    "\n",
    "  print \"\\nSmooth MaxPool Grad:\"\n",
    "  print \"(note the subtle checkerboard patterns)\\n\"\n",
    "\n",
    "  spatial_spatial_attr(img, layer1, layer2,\n",
    "                       hint_label_1=hint_label_1, hint_label_2=hint_label_2,\n",
    "                       override={\"MaxPool\": make_MaxSmoothPoolGrad()})\n",
    "\n",
    "  print \"\\nSmooth + Blur MaxPool Grad:\\n\"\n",
    "\n",
    "  spatial_spatial_attr(img, layer1, layer2,\n",
    "                       hint_label_1=hint_label_1, hint_label_2=hint_label_2,\n",
    "                       override={\"MaxPool\": make_MaxSmoothPoolGrad(blur_hack=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load(\"https://storage.googleapis.com/lucid-static/building-blocks/examples/dog_cat.png\")\n",
    "\n",
    "compare_attrs(img, \"mixed4d\", \"mixed5a\", \"Labrador retriever\", \"tiger cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load(\"https://storage.googleapis.com/lucid-static/building-blocks/examples/flowers.png\")\n",
    "\n",
    "compare_attrs(img, \"mixed4d\", \"mixed5a\", \"lemon\", \"vase\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucidcpu",
   "language": "python",
   "name": "lucidcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
